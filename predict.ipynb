{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import os\n# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  #（保证程序cuda序号与实际cuda序号对应）\n# os.environ['CUDA_VISIBLE_DEVICES'] = \"1,2\"  #（代表仅使用第1，2号GPU）\n\nimport pandas as pd\nimport time\nimport functools\nimport numpy as np\nimport paddle\nimport paddlenlp\nimport paddle.nn.functional as F\nfrom paddle.io import DataLoader, BatchSampler\nfrom paddlenlp.datasets import MapDataset\nfrom paddlenlp.transformers import AutoModelForSequenceClassification, AutoTokenizer\nfrom paddlenlp.data import DataCollatorWithPadding\n\n# 构建验证集evaluate函数\n@paddle.no_grad()\ndef evaluate(model, criterion, metric, data_loader):\n    model.eval()\n    metric.reset()\n    losses = []\n    for batch in data_loader:\n        input_ids, token_type_ids, labels = batch['input_ids'], batch['token_type_ids'], batch['labels']\n\n        logits = model(input_ids, token_type_ids)\n        loss = criterion(logits, labels)\n        losses.append(loss.numpy())\n        correct = metric.compute(logits, labels)\n        metric.update(correct)\n        \n    accu = metric.accumulate()\n    print(\"eval loss: %.5f, accuracy: %.5f\" % (np.mean(losses), accu))\n    model.train()\n    metric.reset()\n    return accu\n\n# 数据预处理函数，利用分词器将文本转化为整数序列\ndef preprocess_function(examples, tokenizer, max_seq_length, is_test=False):\n\n    result = tokenizer(text=examples[\"text\"], max_seq_len=max_seq_length)\n    if not is_test:\n        result[\"labels\"] = examples[\"label\"]\n    return result\n","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:46:27.832420Z","iopub.execute_input":"2022-11-24T03:46:27.832798Z","iopub.status.idle":"2022-11-24T03:46:27.845108Z","shell.execute_reply.started":"2022-11-24T03:46:27.832766Z","shell.execute_reply":"2022-11-24T03:46:27.844188Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"testdata = pd.read_csv('/kaggle/input/datav4/dev.csv', sep=None, header=0, encoding='utf-8', engine='python')\ntest_ds=MapDataset([{'text':d.text,'label':\"\",'qid':str(d.qid)} for d in testdata.itertuples()])","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:46:32.336993Z","iopub.execute_input":"2022-11-24T03:46:32.337346Z","iopub.status.idle":"2022-11-24T03:46:33.051084Z","shell.execute_reply.started":"2022-11-24T03:46:32.337316Z","shell.execute_reply":"2022-11-24T03:46:33.049948Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#引入预训练模型\nmodel_name = \"ernie-3.0-xbase-zh\"\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_classes=7)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n#引入参数\nparams_path=\"/kaggle/input/modeld/model_state.pdparams\"\nstate_dict = paddle.load(params_path)\nmodel.set_dict(state_dict)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:46:35.732274Z","iopub.execute_input":"2022-11-24T03:46:35.732639Z","iopub.status.idle":"2022-11-24T03:46:42.002636Z","shell.execute_reply.started":"2022-11-24T03:46:35.732609Z","shell.execute_reply":"2022-11-24T03:46:42.001622Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"\u001b[32m[2022-11-24 03:46:35,734] [    INFO]\u001b[0m - We are using <class 'paddlenlp.transformers.ernie.modeling.ErnieForSequenceClassification'> to load 'ernie-3.0-xbase-zh'.\u001b[0m\n\u001b[32m[2022-11-24 03:46:35,737] [    INFO]\u001b[0m - Already cached /root/.paddlenlp/models/ernie-3.0-xbase-zh/ernie_3.0_xbase_zh.pdparams\u001b[0m\n\u001b[32m[2022-11-24 03:46:39,895] [    INFO]\u001b[0m - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load 'ernie-3.0-xbase-zh'.\u001b[0m\n\u001b[32m[2022-11-24 03:46:39,896] [    INFO]\u001b[0m - Already cached /root/.paddlenlp/models/ernie-3.0-xbase-zh/ernie_3.0_xbase_zh_vocab.txt\u001b[0m\n\u001b[32m[2022-11-24 03:46:39,926] [    INFO]\u001b[0m - tokenizer config file saved in /root/.paddlenlp/models/ernie-3.0-xbase-zh/tokenizer_config.json\u001b[0m\n\u001b[32m[2022-11-24 03:46:39,927] [    INFO]\u001b[0m - Special tokens file saved in /root/.paddlenlp/models/ernie-3.0-xbase-zh/special_tokens_map.json\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# collate_fn函数构造，将不同长度序列充到批中数据的最大长度，再将数据堆叠\ncollate_fn = DataCollatorWithPadding(tokenizer)\n\n# 测试集数据预处理，利用分词器将文本转化为整数序列\ntrans_func_test = functools.partial(preprocess_function, tokenizer=tokenizer, max_seq_length=128, is_test=True)\ntest_ds_trans = test_ds.map(trans_func_test)\n\n# 进行采样组batch\ncollate_fn_test = DataCollatorWithPadding(tokenizer)\ntest_batch_sampler = BatchSampler(test_ds_trans, batch_size=16, shuffle=False)\ntest_data_loader = DataLoader(dataset=test_ds_trans, batch_sampler=test_batch_sampler, collate_fn=collate_fn_test)\n\n# 模型预测分类结果\nlabel_map={0:\"none\",1:\"happiness\",2:\"sadness\",3:\"anger\",4:\"surprise\",5:\"fear\",6:\"disgust\"}\nresults = []\nprobs_for_8=[]\nmodel.eval()\nk=0\nfor batch in test_data_loader:\n    if k%200==0:\n        print(k)  \n    input_ids, token_type_ids = batch['input_ids'], batch['token_type_ids']\n    logits = model(batch['input_ids'], batch['token_type_ids'])\n    probs = F.softmax(logits, axis=-1)\n    #存储标签\n    idx = paddle.argmax(probs, axis=1).numpy()\n    idx = idx.tolist()\n    preds = [label_map[i] for i in idx]\n    results.extend(preds)\n    #存储可能性\n    probs=probs.numpy()\n    probs=probs.tolist()\n    probs_for_8.extend([i for i in probs])\n    k+=1\n","metadata":{"execution":{"iopub.status.busy":"2022-11-24T03:46:45.815535Z","iopub.execute_input":"2022-11-24T03:46:45.815892Z","iopub.status.idle":"2022-11-24T03:56:36.340131Z","shell.execute_reply.started":"2022-11-24T03:46:45.815860Z","shell.execute_reply":"2022-11-24T03:56:36.339135Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"0\n200\n400\n600\n800\n1000\n1200\n1400\n1600\n1800\n2000\n2200\n2400\n2600\n2800\n3000\n3200\n3400\n","output_type":"stream"}]},{"cell_type":"code","source":"# 存储预测结果  \ntestdata = pd.read_csv('/kaggle/input/datav4/dev.csv', sep=None, header=0, encoding='utf-8', engine='python')\ntest_ds=MapDataset([{'text':d.text,'label':\"\",'qid':str(d.qid),'date':str(d.date),'bid':d.bid} for d in testdata.itertuples()])\n\nres_dir = \"./results\"\nif not os.path.exists(res_dir):\n    os.makedirs(res_dir)\nwith open(os.path.join(res_dir, \"weibosenti\"+str(time.time())+\".csv\"), 'w', encoding=\"utf8\") as f:\n    f.write(\"qid@@text@@prediction@@date@@bid@@none@@happiness@@sadness@@anger@@surprise@@fear@@disgust\\n\")\n    for i, pred in enumerate(results):\n        f.write(test_ds[i]['qid']+\"@@\"+test_ds[i]['text']+\"@@\"+pred+\"@@\"+test_ds[i]['date']+\"@@\"+test_ds[i]['bid']+\"@@\"+\\\n            str(probs_for_8[i][0])+\"@@\"+str(probs_for_8[i][1])+\"@@\"+str(probs_for_8[i][2])+\"@@\"+str(probs_for_8[i][3])+\"@@\"+\\\n            str(probs_for_8[i][4])+\"@@\"+str(probs_for_8[i][5])+\"@@\"+str(probs_for_8[i][6])+\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:00:29.705953Z","iopub.execute_input":"2022-11-24T04:00:29.706321Z","iopub.status.idle":"2022-11-24T04:00:31.489827Z","shell.execute_reply.started":"2022-11-24T04:00:29.706290Z","shell.execute_reply":"2022-11-24T04:00:31.488843Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"probs_for_8[1]","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:03:25.105237Z","iopub.execute_input":"2022-11-24T04:03:25.105653Z","iopub.status.idle":"2022-11-24T04:03:25.114059Z","shell.execute_reply.started":"2022-11-24T04:03:25.105618Z","shell.execute_reply":"2022-11-24T04:03:25.113088Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[0.0006404470186680555,\n 0.8849683403968811,\n 0.008866476826369762,\n 0.06725722551345825,\n 0.012095137499272823,\n 0.0008301167981699109,\n 0.025342129170894623]"},"metadata":{}}]}]}